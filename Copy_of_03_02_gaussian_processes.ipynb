{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2b2c5bec",
      "metadata": {
        "id": "2b2c5bec"
      },
      "source": [
        "# Gaussian Processes\n",
        "\n",
        "### Neil D. Lawrence\n",
        "\n",
        "### 2025-09-16"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7355381",
      "metadata": {
        "id": "e7355381"
      },
      "source": [
        "**Abstract**: Gaussian processes are non parameteric Bayesian models\n",
        "that extend the idea of Bayesian linear models to infinite basis\n",
        "functions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f573d70",
      "metadata": {
        "id": "4f573d70"
      },
      "source": [
        "$$\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9e5db6d",
      "metadata": {
        "id": "a9e5db6d"
      },
      "source": [
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!---->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
        "<!--\n",
        "\n",
        "-->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc769e14",
      "metadata": {
        "id": "bc769e14"
      },
      "source": [
        "## ML Foundations Course Notebook Setup\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_mlfc/includes/mlfc-notebook-setup.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_mlfc/includes/mlfc-notebook-setup.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We install some bespoke codes for creating and saving plots as well as\n",
        "loading data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923d86cf",
      "metadata": {
        "id": "923d86cf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install notutils\n",
        "%pip install pods\n",
        "%pip install git+https://github.com/lawrennd/mlai.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35dab01b",
      "metadata": {
        "id": "35dab01b"
      },
      "outputs": [],
      "source": [
        "import notutils\n",
        "import pods\n",
        "import mlai\n",
        "import mlai.plot as plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "806cbe04",
      "metadata": {
        "id": "806cbe04"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 22})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94f3cb9c",
      "metadata": {
        "id": "94f3cb9c"
      },
      "source": [
        "<!--setupplotcode{import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "sns.set_context('paper')\n",
        "sns.set_palette('colorblind')}-->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a0989df",
      "metadata": {
        "id": "7a0989df"
      },
      "source": [
        "## Review\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/gaussian-processes.gpp.markdown\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/gaussian-processes.gpp.markdown', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Gaussian processes are initially of interest because\n",
        "\n",
        "1.  linear Gaussian models are easier to deal with\n",
        "2.  Even the parameters *within* the process can be handled, by\n",
        "    considering a particular limit."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa8c3fb4",
      "metadata": {
        "id": "fa8c3fb4"
      },
      "source": [
        "## Linear Model Overview\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/linear-model-overview.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/linear-model-overview.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "However, we are focussing on what happens in models which are non-linear\n",
        "in the inputs, whereas the above would be *linear* in the inputs. To\n",
        "consider these, we introduce a matrix, called the design matrix. We set\n",
        "each activation function computed at each data point to be $$\n",
        "\\phi_{i,j} = \\phi(\\mathbf{ w}^{(1)}_{j}, \\mathbf{ x}_{i})\n",
        "$$ and define the matrix of activations (known as the *design matrix* in\n",
        "statistics) to be, $$\n",
        "\\boldsymbol{ \\Phi}=\n",
        "\\begin{bmatrix}\n",
        "\\phi_{1, 1} & \\phi_{1, 2} & \\dots & \\phi_{1, h} \\\\\n",
        "\\phi_{1, 2} & \\phi_{1, 2} & \\dots & \\phi_{1, n} \\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "\\phi_{n, 1} & \\phi_{n, 2} & \\dots & \\phi_{n, h}\n",
        "\\end{bmatrix}.\n",
        "$$ By convention this matrix always has $n$ rows and $h$ columns, now if\n",
        "we define the vector of all noise corruptions,\n",
        "$\\boldsymbol{ \\epsilon}= \\left[\\epsilon_1, \\dots \\epsilon_n\\right]^\\top$.\n",
        "\n",
        "If we define the prior distribution over the vector $\\mathbf{ w}$ to be\n",
        "Gaussian, $$\n",
        "\\mathbf{ w}\\sim \\mathscr{N}\\left(\\mathbf{0},\\alpha\\mathbf{I}\\right),\n",
        "$$ then we can use rules of multivariate Gaussians to see that, $$\n",
        "\\mathbf{ y}\\sim \\mathscr{N}\\left(\\mathbf{0},\\alpha \\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top + \\sigma^2 \\mathbf{I}\\right).\n",
        "$$\n",
        "\n",
        "In other words, our training data is distributed as a multivariate\n",
        "Gaussian, with zero mean and a covariance given by $$\n",
        "\\mathbf{K}= \\alpha \\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top + \\sigma^2 \\mathbf{I}.\n",
        "$$\n",
        "\n",
        "This is an $n\\times n$ size matrix. Its elements are in the form of a\n",
        "function. The maths shows that any element, index by $i$ and $j$, is a\n",
        "function *only* of inputs associated with data points $i$ and $j$,\n",
        "$\\mathbf{ y}_i$, $\\mathbf{ y}_j$.\n",
        "$k_{i,j} = k\\left(\\mathbf{ x}_i, \\mathbf{ x}_j\\right)$\n",
        "\n",
        "If we look at the portion of this function associated only with\n",
        "$f(\\cdot)$, i.e.Â we remove the noise, then we can write down the\n",
        "covariance associated with our neural network, $$\n",
        "k_f\\left(\\mathbf{ x}_i, \\mathbf{ x}_j\\right) = \\alpha \\boldsymbol{ \\phi}\\left(\\mathbf{W}_1, \\mathbf{ x}_i\\right)^\\top \\boldsymbol{ \\phi}\\left(\\mathbf{W}_1, \\mathbf{ x}_j\\right)\n",
        "$$ so the elements of the covariance or *kernel* matrix are formed by\n",
        "inner products of the rows of the *design matrix*."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956e370e",
      "metadata": {
        "id": "956e370e"
      },
      "source": [
        "## Gaussian Process\n",
        "\n",
        "This is the essence of a Gaussian process. Instead of making assumptions\n",
        "about our density over each data point, $y_i$ as i.i.d. we make a joint\n",
        "Gaussian assumption over our data. The covariance matrix is now a\n",
        "function of both the parameters of the activation function,\n",
        "$\\mathbf{V}$, and the input variables, $\\mathbf{X}$. This comes about\n",
        "through integrating out the parameters of the model, $\\mathbf{ w}$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baadc35f",
      "metadata": {
        "id": "baadc35f"
      },
      "source": [
        "## Basis Functions\n",
        "\n",
        "We can basically put anything inside the basis functions, and many\n",
        "people do. These can be deep kernels (Cho and Saul, 2009) or we can\n",
        "learn the parameters of a convolutional neural network inside there.\n",
        "\n",
        "Viewing a neural network in this way is also what allows us to beform\n",
        "sensible *batch* normalizations (Ioffe and Szegedy, 2015)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0de944d",
      "metadata": {
        "id": "f0de944d"
      },
      "source": [
        "## Gaussian Processes\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-lectures.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-lectures.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Models where we model the entire joint distribution of our training\n",
        "data, $p(\\mathbf{ y}, \\mathbf{X})$ are sometimes described as\n",
        "*generative models*. Because we can use sampling to generate data sets\n",
        "that represent all our assumptions. However, as we discussed in the\n",
        "sessions on and , this can be a bad idea, because if our assumptions are\n",
        "wrong then we can make poor predictions. We can try to make more complex\n",
        "assumptions about data to alleviate the problem, but then this typically\n",
        "leads to challenges for tractable application of the sum and rules of\n",
        "probability that are needed to compute the relevant marginal and\n",
        "conditional densities. If we know the form of the question we wish to\n",
        "answer then we typically try and represent that directly, through\n",
        "$p(\\mathbf{ y}|\\mathbf{X})$. In practice, we also have been making\n",
        "assumptions of conditional independence given the model parameters, $$\n",
        "p(\\mathbf{ y}|\\mathbf{X}, \\mathbf{ w}) =\n",
        "\\prod_{i=1}^{n} p(y_i | \\mathbf{ x}_i, \\mathbf{ w})\n",
        "$$ Gaussian processes are *not* normally considered to be *generative\n",
        "models*, but we will be much more interested in the principles of\n",
        "conditioning in Gaussian processes because we will use conditioning to\n",
        "make predictions between our test and training data. We will avoid the\n",
        "data conditional indpendence assumption in favour of a richer assumption\n",
        "about the data, in a Gaussian process we assume data is *jointly\n",
        "Gaussian* with a particular mean and covariance, $$\n",
        "\\mathbf{ y}|\\mathbf{X}\\sim \\mathscr{N}\\left(\\mathbf{m}(\\mathbf{X}),\\mathbf{K}(\\mathbf{X})\\right),\n",
        "$$ where the conditioning is on the inputs $\\mathbf{X}$ which are used\n",
        "for computing the mean and covariance. For this reason they are known as\n",
        "mean and covariance functions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c691368d",
      "metadata": {
        "id": "c691368d"
      },
      "source": [
        "## Prediction Across Two Points with GPs\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gptwopointpred.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gptwopointpred.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c7e1018",
      "metadata": {
        "id": "6c7e1018"
      },
      "source": [
        "## Sampling a Function\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gaussian-predict-index-one-and-two.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gaussian-predict-index-one-and-two.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We will consider a *multivariate Gaussian* with a particular structure\n",
        "of covariance matrix. We will generate a *single* sample from this 25\n",
        "dimensional Gaussian density.\n",
        "\n",
        "$$\n",
        "\\mathbf{ f}=\\left[f_{1},f_{2}\\dots f_{25}\\right].\n",
        "$$ in the figure below we plot these data on the $y$-axis against their\n",
        "*indices* on the $x$-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a848f06f",
      "metadata": {
        "id": "a848f06f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(4949)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e080b8",
      "metadata": {
        "id": "15e080b8"
      },
      "outputs": [],
      "source": [
        "from mlai import Kernel\n",
        "import inspect\n",
        "file_path = inspect.getfile(Kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cb319c7",
      "metadata": {
        "id": "4cb319c7"
      },
      "outputs": [],
      "source": [
        "%load -s Kernel {file_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3c7df97",
      "metadata": {
        "id": "f3c7df97"
      },
      "outputs": [],
      "source": [
        "from mlai import polynomial_cov\n",
        "import inspect\n",
        "file_path = inspect.getfile(polynomial_cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81901a56",
      "metadata": {
        "id": "81901a56"
      },
      "outputs": [],
      "source": [
        "%load -s polynomial_cov {file_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ad61593",
      "metadata": {
        "id": "0ad61593"
      },
      "outputs": [],
      "source": [
        "from mlai import eq_cov\n",
        "import inspect\n",
        "file_path = inspect.getfile(eq_cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd70130f",
      "metadata": {
        "id": "cd70130f"
      },
      "outputs": [],
      "source": [
        "%load -s eq_cov {file_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bcbbf39",
      "metadata": {
        "id": "1bcbbf39"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e08bb60e",
      "metadata": {
        "id": "e08bb60e"
      },
      "outputs": [],
      "source": [
        "kernel=Kernel(function=eq_cov, lengthscale=0.5)\n",
        "plot.two_point_sample(kernel.K, diagrams='./gp')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a687578",
      "metadata": {
        "id": "0a687578"
      },
      "source": [
        "### Sampling a Function from a Gaussian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "964b6c84",
      "metadata": {
        "id": "964b6c84"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3c00343",
      "metadata": {
        "id": "e3c00343"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abc0f0f2",
      "metadata": {
        "id": "abc0f0f2"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('two_point_sample{sample:0>3}.svg',\n",
        "                            './gp',\n",
        "                            sample=IntSlider(0, 0, 8, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cacdbec3",
      "metadata": {
        "id": "cacdbec3"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample001.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The joint Gaussian over $f_1$ and $f_2$ along with the\n",
        "conditional distribution of $f_2$ given $f_1$</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6554241f",
      "metadata": {
        "id": "6554241f"
      },
      "source": [
        "### Joint Density of $f_1$ and $f_2$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3fb3411",
      "metadata": {
        "id": "a3fb3411"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87e7be2",
      "metadata": {
        "id": "b87e7be2"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d6a90f",
      "metadata": {
        "id": "77d6a90f"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('two_point_sample{sample:0>3}.svg',\n",
        "                            './gp',\n",
        "                            sample=IntSlider(9, 9, 12, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc25353c",
      "metadata": {
        "id": "bc25353c"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample012.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The joint Gaussian over $f_1$ and $f_2$ along with the\n",
        "conditional distribution of $f_2$ given $f_1$</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fb055b2",
      "metadata": {
        "id": "0fb055b2"
      },
      "source": [
        "## Uluru\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/799px-Uluru_Panorama.jpg\" style=\"width:\">\n",
        "\n",
        "Figure: <i>Uluru, the sacred rock in Australia. If we think of it as a\n",
        "probability density, viewing it from this side gives us one *marginal*\n",
        "from the density. Figuratively speaking, slicing through the rock would\n",
        "give a conditional density.</i>\n",
        "\n",
        "When viewing these contour plots, I sometimes find it helpful to think\n",
        "of Uluru, the prominent rock formation in Australia. The rock rises\n",
        "above the surface of the plane, just like a probability density rising\n",
        "above the zero line. The rock is three dimensional, but when we view\n",
        "Uluru from the classical position, we are looking at one side of it.\n",
        "This is equivalent to viewing the marginal density.\n",
        "\n",
        "The joint density can be viewed from above, using contours. The\n",
        "conditional density is equivalent to *slicing* the rock. Uluru is a holy\n",
        "rock, so this has to be an imaginary slice. Imagine we cut down a\n",
        "vertical plane orthogonal to our view point (e.g.Â coming across our view\n",
        "point). This would give a profile of the rock, which when renormalized,\n",
        "would give us the conditional distribution, the value of conditioning\n",
        "would be the location of the slice in the direction we are facing."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca219bc4",
      "metadata": {
        "id": "ca219bc4"
      },
      "source": [
        "## Prediction of $f_2$ from $f_1$\n",
        "\n",
        "Of course in practice, rather than manipulating mountains physically,\n",
        "the advantage of the Gaussian density is that we can perform these\n",
        "manipulations mathematically.\n",
        "\n",
        "Prediction of $f_2$ given $f_1$ requires the *conditional density*,\n",
        "$p(f_2|f_1)$.Another remarkable property of the Gaussian density is that\n",
        "this conditional distribution is *also* guaranteed to be a Gaussian\n",
        "density. It has the form, $$\n",
        "p(f_2|f_1) = \\mathscr{N}\\left(f_2|\\frac{k_{1, 2}}{k_{1, 1}}f_1, k_{2, 2} - \\frac{k_{1,2}^2}{k_{1,1}}\\right)\n",
        "$$where we have assumed that the covariance of the original joint\n",
        "density was given by $$\n",
        "\\mathbf{K}= \\begin{bmatrix} k_{1, 1} & k_{1, 2}\\\\ k_{2, 1} & k_{2, 2}.\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Using these formulae we can determine the conditional density for any of\n",
        "the elements of our vector $\\mathbf{ f}$. For example, the variable\n",
        "$f_8$ is less correlated with $f_1$ than $f_2$. If we consider this\n",
        "variable we see the conditional density is more diffuse."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71d1d68d",
      "metadata": {
        "id": "71d1d68d"
      },
      "source": [
        "### Joint Density of $f_1$ and $f_8$\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gaussian-predict-index-one-and-eight.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gaussian-predict-index-one-and-eight.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc3b95c",
      "metadata": {
        "id": "0bc3b95c"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32eae333",
      "metadata": {
        "id": "32eae333"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e107cad0",
      "metadata": {
        "id": "e107cad0"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('two_point_sample{sample:0>3}.svg',\n",
        "                            './gp',\n",
        "                            sample=IntSlider(13, 13, 17, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e62a43a",
      "metadata": {
        "id": "2e62a43a"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample013.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Sample from the joint Gaussian model, points indexed by 1 and\n",
        "8 highlighted.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e54266fd",
      "metadata": {
        "id": "e54266fd"
      },
      "source": [
        "### Prediction of $f_{8}$ from $f_{1}$\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample017.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The joint Gaussian over $f_1$ and $f_8$ along with the\n",
        "conditional distribution of $f_8$ given $f_1$</i>\n",
        "\n",
        "-   The single contour of the Gaussian density represents the\n",
        "    <font color=\"blue\">joint distribution, $p(f_1, f_8)$</font>\n",
        "\n",
        ". . .\n",
        "\n",
        "-   We observe a value for <font color=\"green\">$f_1=-?$</font>\n",
        "\n",
        ". . .\n",
        "\n",
        "-   Conditional density: <font color=\"red\">$p(f_8|f_1=?)$</font>.\n",
        "\n",
        "-   Prediction of $\\mathbf{ f}_*$ from $\\mathbf{ f}$.\n",
        "\n",
        "-   Multivariate conditional density is *also* Gaussian. $$\n",
        "    p(\\mathbf{ f}_*|\\mathbf{ f}) = {\\mathcal{N}\\left(\\mathbf{ f}_*|\\mathbf{K}_{*,\\mathbf{ f}}\\mathbf{K}_{\\mathbf{ f},\\mathbf{ f}}^{-1}\\mathbf{ f},\\mathbf{K}_{*,*}-\\mathbf{K}_{*,\\mathbf{ f}} \\mathbf{K}_{\\mathbf{ f},\\mathbf{ f}}^{-1}\\mathbf{K}_{\\mathbf{ f},*}\\right)}\n",
        "    $$\n",
        "\n",
        "-   Here covariance of joint density is given by $$\n",
        "    \\mathbf{K}= \\begin{bmatrix} \\mathbf{K}_{\\mathbf{ f}, \\mathbf{ f}} & \\mathbf{K}_{*, \\mathbf{ f}}\\\\ \\mathbf{K}_{\\mathbf{ f}, *} & \\mathbf{K}_{*, *}\\end{bmatrix}\n",
        "    $$\n",
        "\n",
        "-   Prediction of $\\mathbf{ f}_*$ from $\\mathbf{ f}$.\n",
        "\n",
        "-   Multivariate conditional density is *also* Gaussian. $$\n",
        "    p(\\mathbf{ f}_*|\\mathbf{ f}) = {\\mathcal{N}\\left(\\mathbf{ f}_*|\\boldsymbol{ \\mu},\\boldsymbol{ \\Sigma}\\right)}\n",
        "    $$ $$\n",
        "    \\boldsymbol{ \\mu}= \\mathbf{K}_{*,\\mathbf{ f}}\\mathbf{K}_{\\mathbf{ f},\\mathbf{ f}}^{-1}\\mathbf{ f}\n",
        "    $$ $$\n",
        "    \\boldsymbol{ \\Sigma}= \\mathbf{K}_{*,*}-\\mathbf{K}_{*,\\mathbf{ f}} \\mathbf{K}_{\\mathbf{ f},\\mathbf{ f}}^{-1}\\mathbf{K}_{\\mathbf{ f},*}\n",
        "    $$\n",
        "\n",
        "-   Here covariance of joint density is given by $$\n",
        "    \\mathbf{K}= \\begin{bmatrix} \\mathbf{K}_{\\mathbf{ f}, \\mathbf{ f}} & \\mathbf{K}_{*, \\mathbf{ f}}\\\\ \\mathbf{K}_{\\mathbf{ f}, *} & \\mathbf{K}_{*, *}\\end{bmatrix}\n",
        "    $$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c44a463",
      "metadata": {
        "id": "8c44a463"
      },
      "source": [
        "## Where Did This Covariance Matrix Come From?\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_kern/includes/computing-rbf-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/computing-rbf-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "$$\n",
        "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left(-\\frac{\\left\\Vert \\mathbf{ x}- \\mathbf{ x}^\\prime\\right\\Vert^2_2}{2\\ell^2}\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42d798da",
      "metadata": {
        "id": "42d798da"
      },
      "outputs": [],
      "source": [
        "from mlai import Kernel\n",
        "import inspect\n",
        "file_path = inspect.getfile(Kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9e6341d",
      "metadata": {
        "id": "e9e6341d"
      },
      "outputs": [],
      "source": [
        "%load -s Kernel {file_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c20516",
      "metadata": {
        "id": "64c20516"
      },
      "outputs": [],
      "source": [
        "from mlai import eq_cov\n",
        "import inspect\n",
        "file_path = inspect.getfile(eq_cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f260d5cd",
      "metadata": {
        "id": "f260d5cd"
      },
      "outputs": [],
      "source": [
        "%load -s eq_cov {file_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2220b475",
      "metadata": {
        "id": "2220b475"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import mlai\n",
        "import mlai.plot as plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2333e98",
      "metadata": {
        "id": "e2333e98"
      },
      "outputs": [],
      "source": [
        "formula = r\"$k(x_i, x_j)=\\alpha\\exp\\left(-\\frac{\\left|\\left|x_i-x_j\\right|\\right|^{2}}{2\\ell^{2}}\\right)$\"\n",
        "kernel = mlai.Kernel(mlai.eq_cov, lengthscale=2.0, variance=1.0)\n",
        "plot.computing_covariance(kernel=kernel, x=np.asarray([[-3.],[1.2], [1.4]]),\n",
        "                          formula=formula,\n",
        "                          stub='eq_three',\n",
        "                          diagrams='./kern')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "463cefce",
      "metadata": {
        "id": "463cefce"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3110f2bc",
      "metadata": {
        "id": "3110f2bc"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d433e3",
      "metadata": {
        "id": "23d433e3"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('computing_eq_three_covariance{sample:0>3}.svg',\n",
        "                            directory='./kern',\n",
        "                            sample=IntSlider(0, 0, 16, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fd14668",
      "metadata": {
        "id": "6fd14668"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//kern/computing_eq_three_covariance016.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Entrywise fill in of the covariance matrix from the\n",
        "covariance function.</i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e98815",
      "metadata": {
        "id": "b4e98815"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from mlai import exponentiated_quadratic, Kernel\n",
        "import mlai.plot as plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dbcafff",
      "metadata": {
        "id": "7dbcafff"
      },
      "outputs": [],
      "source": [
        "formula = r\"$k(x_i, x_j)=\\alpha\\exp\\left(-\\frac{\\left|\\left|x_i-x_j\\right|\\right|^{2}}{2\\ell^{2}}\\right)$\"\n",
        "kernel = mlai.Kernel(mlai.eq_cov, lengthscale=2.0, variance=1.0)\n",
        "plot.computing_covariance(kernel=kernel, x=np.asarray([[-3.],[1.2], [1.4], [2.0]]),\n",
        "                          formula=formula,\n",
        "                          stub='eq_four',\n",
        "                          diagrams='./kern')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d7962d3",
      "metadata": {
        "id": "7d7962d3"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0fce546",
      "metadata": {
        "id": "c0fce546"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17bb25e",
      "metadata": {
        "id": "c17bb25e"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('computing_eq_four_covariance{sample:0>3}.svg',\n",
        "                            directory='./kern',\n",
        "                            sample=IntSlider(0, 0, 27, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a498e0e",
      "metadata": {
        "id": "6a498e0e"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//kern/computing_eq_four_covariance027.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Entrywise fill in of the covariance matrix from the\n",
        "covariance function.</i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bf56564",
      "metadata": {
        "id": "7bf56564"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from mlai import exponentiated_quadratic, Kernel\n",
        "import mlai.plot as plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ab1d26",
      "metadata": {
        "id": "30ab1d26"
      },
      "outputs": [],
      "source": [
        "formula = r\"$k(x_i, x_j)=\\alpha\\exp\\left(-\\frac{\\left|\\left|x_i-x_j\\right|\\right|^{2}}{2\\ell^{2}}\\right)$\"\n",
        "kernel = mlai.Kernel(mlai.eq_cov, lengthscale=5.0, variance=2.0)\n",
        "plot.computing_covariance(kernel=kernel, x=np.asarray([[-3.],[1.2], [1.4]]),\n",
        "                          formula=formula,\n",
        "                          stub='eq_three_2',\n",
        "                          diagrams='./kern')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "522abedc",
      "metadata": {
        "id": "522abedc"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "848768b5",
      "metadata": {
        "id": "848768b5"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b6c779",
      "metadata": {
        "id": "42b6c779"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('computing_eq_three_2_covariance{sample:0>3}.svg',\n",
        "                            directory='./kern',\n",
        "                            sample=IntSlider(0, 0, 16, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0540b9ae",
      "metadata": {
        "id": "0540b9ae"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//kern/computing_eq_three_2_covariance016.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Entrywise fill in of the covariance matrix from the\n",
        "covariance function.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a08e4a92",
      "metadata": {
        "id": "a08e4a92"
      },
      "source": [
        "## Thanks!\n",
        "\n",
        "For more information on these subjects and more you might want to check\n",
        "the following resources.\n",
        "\n",
        "-   company: [Trent AI](https://trent.ai)\n",
        "-   book: [The Atomic\n",
        "    Human](https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248)\n",
        "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
        "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
        "-   newspaper: [Guardian Profile\n",
        "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
        "-   blog:\n",
        "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c32b9407",
      "metadata": {
        "id": "c32b9407"
      },
      "source": [
        "::: {.cell .markdown}\n",
        "\n",
        "## References\n",
        "\n",
        "Cho, Y., Saul, L.K., 2009. Kernel methods for deep learning, in: Bengio,\n",
        "Y., Schuurmans, D., Lafferty, J.D., Williams, C.K.I., Culotta, A.\n",
        "(Eds.), Advances in Neural Information Processing Systems 22. Curran\n",
        "Associates, Inc., pp. 342â350.\n",
        "\n",
        "Ioffe, S., Szegedy, C., 2015. Batch normalization: Accelerating deep\n",
        "network training by reducing internal covariate shift, in: Bach, F.,\n",
        "Blei, D. (Eds.), Proceedings of the 32nd International Conference on\n",
        "Machine Learning, Proceedings of Machine Learning Research. PMLR, Lille,\n",
        "France, pp. 448â456."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}